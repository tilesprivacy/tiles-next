---
title: "Manual"
description: "Command-line interface reference for Tiles and Tilekit, with usage examples"
---

# Manual

Reminder: this is in alpha.

Enjoy these sample commands in lieu of a formal doc.

## Tiles

Commands in this section are meant for regular users.

### CLI Commands

```bash
tiles run [MODELFILE_PATH]     # Run a model (uses default if path not provided)
tiles run -r <count>           # Set max relay count for model communication (default: 10)
tiles health                   # Check status of dependencies
tiles memory set-path <path>   # Set the path for memory storage
tiles server start             # Start the daemon server
tiles server stop              # Stop the daemon server
```

### Examples

```bash
# Start chatting with the default model
tiles run

# Run a specific Modelfile
tiles run ./path/to/Modelfile

# Check if all dependencies are properly installed
tiles health

# Configure memory storage location
tiles memory set-path ~/.tiles/memory

# Start the background server
tiles server start
```

## Tilekit

Commands in this section are meant for developers.

### CLI Commands

```bash
tiles optimize <MODELFILE_PATH> [--data <path>] [--model <provider:model-name>]  # Optimize SYSTEM prompt in Modelfile
```

### Examples

```bash
# Optimize SYSTEM prompt in a Modelfile
tiles optimize path/to/Modelfile

# Optimize with custom training data
tiles optimize ./Modelfile --data training-data.json

# Optimize using a specific model
tiles optimize ./Modelfile --model anthropic:claude-3-5-sonnet-20240620
```

### Optimize Command Details

The `tiles optimize` command refines the `SYSTEM` prompt in your Modelfile automatically using DSRs (dspy-rs) and the COPRO optimizer.

**Basic Usage:**

```bash
tiles optimize path/to/Modelfile
```

By default, this will:
- Generate 5 synthetic examples automatically if you do not provide your own training data
- Use `openai:gpt-4o-mini` as the optimization model
- Update your Modelfile in-place with the improved `SYSTEM` prompt

**Options:**

- `--data <path>` - Provide your own training data as a JSON file
- `--model <provider:model-name>` - Specify a different model to use for optimization

**Requirements:**

Your Modelfile must contain a starting `SYSTEM` prompt, so the optimizer knows what it should build upon.

**Training Data Format:**

If supplying your own data, use JSON structured like this:

```json
[
  {
    "input": "User query here",
    "output": "Expected AI response here"
  }
]
```

**Example:**

Let's say you have a Modelfile:

```text
FROM llama3
SYSTEM "You are a helpful assistant."
```

To optimize its `SYSTEM` prompt using Claude:

```bash
export ANTHROPIC_API_KEY=sk-ant-...
tiles optimize ./Modelfile --model anthropic:claude-3-5-sonnet-20240620
```

This will rewrite the `SYSTEM` line with a more effective version based on the optimization process.
